---
title: Planning in Reward-Rich Domains via PAC Bandits
abstract: In some decision-making environments, successful solutions are common. If
  the evaluation of candidate solutions is noisy, however, the challenge is knowing
  when a “good enough” answer has been found. We formalize this problem as an infinite-armed
  bandit and provide upper and lower bounds on the number of evaluations or “pulls”
  needed to identify a solution whose evaluation exceeds a given threshold r0 . We
  present several algorithms and use them to identify reliable strategies for solving
  screens from the video games \emphInfinite Mario and \emphPitfall! We show order
  of magnitude improvements in sample complexity over a natural approach that pulls
  each arm until a good estimate of its success probability is known.
pdf: http://proceedings.pmlr.press/goschin12a/goschin12a.pdf
layout: inproceedings
id: goschin12a
month: 0
firstpage: 25
lastpage: 42
page: 25-42
origpdf: http://jmlr.org/proceedings/papers/v24/goschin12a/goschin12a.pdf
sections: 
author:
- given: Sergiu
  family: Goschin
- given: Ari
  family: Weinstein
- given: Michael L.
  family: Littman
- given: Erick
  family: Chastain
date: 2013-01-12
publisher: PMLR
container-title: Proceedings of the Tenth European Workshop on Reinforcement Learning
volume: '24'
genre: inproceedings
issued:
  date-parts:
  - 2013
  - 1
  - 12
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
